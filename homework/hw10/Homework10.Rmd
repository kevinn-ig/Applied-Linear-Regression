---
title: 'STA 5207: Homework 10'
date: 'Due: Friday, April 12th by 11:59 PM'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Include your R code in an R chunks as part of your answer. In addition, your written answer to each exercise should be self-contained so that the grader can determine your solution without reading your code or deciphering its output.

```{r, include = FALSE}
library(faraway)
library(carData)
library(quantreg)
library(MASS)
library(car)
library(tidyverse)
```

## Exercise 1 (The `stackloss` Data Set) [50 points]

For this exercise, we will use the `stackloss` data set from the `faraway` package. You can also find the data in `stackloss.csv` on Canvas. The data set contains operational data of a plant for the oxidation of ammonia to nitric acid. There are 21 observations and the following 4 variables in the data set

-   `Air Flow`: Flow of cooling air.
-   `Water Temp`: Cooling Water Inlet Temperature.
-   `Acid Conc.`: Concentration of acid [per 1000, minus 500].
-   `stack.loss`: Stack loss.

In the following exercise, we will use `stack.loss` as the response and `Air Flow`, `Water Temp`, and `Acid Conc.` as predictors.

1.  (4 points) Perform OLS regression with `stack.loss` as the response and the remaining variables as predictors. Check the normality assumption using a hypothesis test at the $\alpha = 0.05$ significance level. Report the $p$-value of the test and your conclusions.

    ```{r}
    model_ols = lm(stack.loss ~ ., data = stackloss)

    shapiro.test(resid(model_ols))

    summary(model_ols)$coeff
    ```

    The test statistic is.974 with a $p$-value of .819, which is greater than the significance level so we do not reject the null hypothesis and conclude the errors have a normal distribution.

2.  (4 points) Perform LAD regression with `stack.loss` as the response and the remaining variables as predictors. Report the estimated regression equation for this model.

    ```{r}
    model_lad = rq(stack.loss ~ ., data = stackloss)

    summary(model_lad, alpha = 0.05)
    ```

    $$
    stack.loss = -39.69 + .831\text{Air.flow}_i + .573\text{Water.temp}_i - .061\text{Acid.conc}_i
    $$

3.  (4 points) Perform robust regression using Huber's method with `stack.loss` as the response and the remaining variables as predictors. Use `maxit = 100` iterations for IRWLS. Report the estimated regression equation for this model.

    ```{r}
    model_hub = rlm(stack.loss ~ ., maxit = 100, data = stackloss)

    summary(model_hub)
    ```

    $$
    stack.loss = -41.03 + .830\text{Air.flow}_i + .926\text{Water.temp}_i - .128\text{Acid.conc}_i
    $$

4.  (4 points) Calculate and report the 95% confidence intervals for the intercept and the slope parameters of the model you fit in Question 3 using the residual bootstrap. Use $R = 2000$ bootstrap samples, `method = 'residual'`, and set a seed of 42.

    ```{r}
    set.seed(42)

    Confint(Boot(model_hub, R = 2000, method = 'residual'))
    ```

    |            |                 |
    |------------|-----------------|
    | Intercept  | (-64.16,-19.63) |
    | Air.Flow   | (.567,1.063)    |
    | Water.Temp | (.230,1.607)    |
    | Acid.Conc. | (-.415,.164)    |

5.  (5 points) Create and report a table comparing the OLS, LAD, and Huber estimates for the intercept *and* slope parameters. Bold entries in the table that are significant at the $\alpha = 0.05$ significance level (for OLS use the standard $t$-test). Recall that for LAD, you should set `alpha = 0.05` in the model `summary`.

    |     | Intercept  | Air.Flow | Water.temp | Acid.Conc. |
    |-----|------------|----------|------------|------------|
    | OLS | **-39.92** | **.716** | **1.30**   | -.152      |
    | LAD | -39.69     | .832     | .574       | **-.061**  |
    | HUB | -41.02     | **.823** | **.926**   | -.128      |

6.  (3 points) Use the OLS model from Question 1 to check for any highly influential data points. Report the observations you determine are highly influential.

    ```{r}
    which(cooks.distance(model_ols) > 4/length(resid(model_ols)))
    ```

    At observation 21 there is a highly influential point.

7.  (3 points) Identify the observations with weights less than one in the Huber fit from Question 3. Report these observations along with their weights. Which (if any) of these observations also have high influence according to Question 6.

    ```{r}
    which(model_hub$w < 1)
    ```

    Observations 3, 4, and 21 have weights less than one. 21 is also a highly influential point.

8.  (5 points) Fit an OLS regression model with the observations that were highly influential removed. Create a table comparing the OLS estimates from the model in Question 1 with these new estimates. Bold entries in the table that are statistically significant at the $\alpha = 0.05$ significance level according to a standard $t$-test for each model.

    ```{r}
    model_ols = lm(stack.loss ~ ., data = stackloss, subset = -21)
    summary(model_ols)$coeff
    ```

    |             | Intercept  | Air.Flow | Water.temp | Acid.Conc. |
    |-------------|------------|----------|------------|------------|
    | OLS         | **-39.92** | **.716** | **1.30**   | -.152      |
    | OLS (refit) | **-43.7**  | **.889** | **.817**   | -.107      |

9.  (5 points) Fit an LAD regression model with the observations that were highly influential removed. Create a table comparing the parameter estimates from the LAD model in Question 2 with these new estimates. Bold entries in the table that are statistically significant at the $\alpha = 0.05$ significance level.

    ```{r}
    model_lad = rq(stack.loss ~ ., data = stackloss, subset = -21)

    summary(model_lad, alpha = .05)
    ```

    |             | Intercept | Air.Flow | Water.temp | Acid.Conc. |
    |-------------|-----------|----------|------------|------------|
    | LAD         | -39.69    | .832     | .574       | **-.061**  |
    | LAD (refit) | -40       | .834     | .564       | **-.0569** |

10. (5 points) Perform robust regression using Huber’s method with the observations that were highly influential removed. Use `maxit = 100` iterations of IRWLS. Calculate and report the 95% confidence intervals for the intercept and slope parameters of this model using the residual bootstrap. Use $R = 2000$ bootstrap samples, `method = 'residual'`, and set a seed of 42.

    ```{r}
    model_hub = rlm(stack.loss ~ ., maxit = 100, data = stackloss[-21,])

    Confint(Boot(model_hub, R = 2000, method = 'residual'))
    summary(model_hub)$coeff
    ```

    |            |                  |
    |------------|------------------|
    | Intercept  | (-58.713,-21.18) |
    | Air.Flow   | (.704,1.154)     |
    | Water.Temp | (-.008,1.267)    |
    | Acid.Conc. | (-.354,.120)     |

11. (5 points) Create a table comparing the parameter estimates from the model using Huber’s method in Question 3 with the new estimates from the model in Question 10. Bold entries in the table that are statistically significant at the $\alpha = 0.05$ significance level.

    |             | Intercept | Air.Flow | Water.temp | Acid.Conc. |
    |-------------|-----------|----------|------------|------------|
    | HUB         | -41.02    | **.823** | **.926**   | -.128      |
    | HUB (refit) | -42.8     | **.918** | **.685**   | -.108      |

12. (3 points) Based on your answers to Questions 8 - 11 and the difference in the slope estimates, which method is most resistant to the highly influential observations. Justify your answer.

    The LAD method seems to be most resistant as the intercept and slope estimates do not change much after removing the influential points.

## Exercise 2 (The `Duncan` Data Set) [50 points]

For this exercise, we will use the `Duncan` data set from the `carData` package. You can also find the data in `Duncan.csv` on Canvas. The data set contains information on the prestige and other characteristics of 45 U.S. occuptations in 1950. There are 45 obervations and the following 4 variables in the data set

-   `type`: Type of occupation (professional and managerial, white-collar, and blue-collar).
-   `income`: Percentage of occupational incumbents in the 1950 U.S. Census who earned \$3,500 or more per year (about \$36,000 in 2017 U.S. dollars).
-   `education`: Percentage of occupational incumbents in 1950 who were high school graduates.
-   `prestige`: Percentage of respondents in a social survey who rated the occupation as "good" or better in prestige.

In the following exercise, we will use `prestige` as the response and `income` and `education` as predictors.

1.  (4 points) Perform OLS regression with `prestige` as the response and `income` and `education` as predictors. Check the normality assumption using a hypothesis test at the $\alpha = 0.05$ significance level. Report the $p$-value of the test and your conclusions.

    ```{r}
    model_ols = lm(prestige ~ . - type, data = Duncan)

    shapiro.test(resid(model_ols))

    summary(model_ols)$coeff
    ```

    The test statistic is.983 with a $p$-value of .723, which is greater than the significance level so we do not reject the null hypothesis and conclude the errors have a normal distribution.

2.  (4 points) Perform LAD regression with `prestige` as the response and `income` and `education` as predictors. Report the estimated regression equation for this model.

    ```{r}
    model_lad = rq(prestige ~ . - type, data = Duncan)

    summary(model_lad, alpha = .05)$coeff
    ```

    $$
    \text{prestige}_i = -6.41 + .748\text{income}_i + .459\text{education}_i
    $$

3.  (4 points) Perform robust regression using Huber's method with `prestige` as the response `income` and `education` as predictors. Use maxit = 50 iterations for IRWLS. Report the estimated regression equation for this model.

    ```{r}
    model_hub = rlm(prestige ~ . - type,maxit = 50, data = Duncan)

    summary(model_hub)$coeff
    ```

    $$
    \text{prestige}_i = -7.11 + .701\text{income}_i + .485\text{education}_i
    $$

4.  (4 points) Calculate and report the 95% confidence intervals for the intercept and the slope parameters of the model you fit in Question 3 using the residual bootstrap. Use $R = 2000$ bootstrap samples, `method = 'residual'`, and set a seed of 42.

    ```{r}
    set.seed(42)

    Confint(Boot(model_hub, R = 2000, method = 'residual'))
    ```

    |           |                |
    |-----------|----------------|
    | Intercept | (-15.24, .121) |
    | Income    | (.482, .931)   |
    | Education | (.310, .670)   |

5.  (5 points) Create and report a table comparing the OLS, LAD, and Huber estimates for the intercept *and* slope parameters. Bold entries in the table that are significant at the $\alpha = 0.05$ significance level (for OLS use the standard $t$-test). Recall that for LAD, you should set `alpha = 0.05` in the model `summary`.

    |     | Intercept | Income   | Education |
    |-----|-----------|----------|-----------|
    | OLS | -6.065    | **.599** | **.546**  |
    | LAD | -6.408    | .748     | .459      |
    | HUB | **-7.11** | **.701** | .485      |

6.  (3 points) Use the OLS model from Question 1 to check for any highly influential data points. Report the observations you determine are highly influential.

    ```{r}
    which(cooks.distance(model_ols) > 4/length(resid(model_ols)))
    ```

    Minister, reporter, and conductor at observation 6,9,16 respectively are highly influential.

7.  (3 points) Identify the five observations that have the lowest weights in the Huber fit from Question 3. Report these observations along with their weights. Which (if any) of these observations also have high influence according to Question 6.

    ```{r}
    # order of the weights going from lowest to heighest
    ord = order(model_hub$w)


    as_tibble(cbind(
        'Occupation' = row.names(Duncan)[ord],  
        'Weight' = model_hub$w[ord]       # ordered weights from huber
    ))
    ```

    Minister, reporter, insurance.agent, conductor, and contractor have the lowest weights. Minister, reporter, and conductor are also the highly influential data points.

8.  (5 points) Fit an OLS regression model with the observations that were highly influential removed. Create a table comparing the OLS estimates from the model in Question 1 with these new estimates. Bold entries in the table that are statistically significant at the $\alpha = 0.05$ significance level according to a standard $t$-test for each model

    ```{r}
    model_ols = lm(prestige ~ . - type, data = Duncan, subset = -c(6,9,16))
    summary(model_ols)$coeff
    ```

    |             | Intercept | Income   | Education |
    |-------------|-----------|----------|-----------|
    | OLS         | -6.065    | **.599** | **.546**  |
    | OLS (refit) | **-7.24** | **.877** | **.353**  |

9.  (5 points) Fit an LAD regression model with the observations that were highly influential removed. Create a table comparing the parameter estimates from the LAD model in Question 2 with these new estimates. Bold entries in the table that are statistically significant at the $\alpha = 0.05$ significance level.

    ```{r}
    model_lad = rq(prestige ~ . - type, data = Duncan,subset = -c(6,9,16))
    summary(model_lad, alpha = .05)$coeff
    ```

    |             | Intercept | Income | Education |
    |-------------|-----------|--------|-----------|
    | LAD         | -6.408    | .748   | .459      |
    | LAD (refit) | -8.62     | .811   | .445      |

10. (5 points) Perform robust regression using Huber’s method with the observations that were highly influential removed. Use `maxit = 50` iterations of IRWLS. Calculate and report the 95% confidence intervals for the intercept and slope parameters of this model using the residual bootstrap. Use $R = 2000$ bootstrap samples, `method = 'residual'`, and set a seed of 42.

    ```{r}
    model_hub = rlm(prestige ~ . - type,maxit = 50, data = Duncan[-c(6,9,16),])

    set.seed(42)

    Confint(Boot(model_hub, R = 2000, method = 'residual'))
    ```

    |           |                  |
    |-----------|------------------|
    | Intercept | (-14.03, -1.701) |
    | Income    | (.630, 1.082)    |
    | Education | (.195, .563)     |

11. (5 points) Create a table comparing the parameter estimates from the model using Huber’s method in Question 3 with the new estimates from the model in Question 10. Bold entries in the table that are statistically significant at the $\alpha = 0.05$ significance level.

    ```{r}
    summary(model_hub)$coeff
    ```

    |             | Intercept | Income   | Education |
    |-------------|-----------|----------|-----------|
    | HUB         | **-7.11** | **.701** | .485      |
    | HUB (refit) | -7.610    | **.855** | **.384**  |

12. (3 points) Based on your answers to Questions 8 - 11 and the difference in the slope estimates, which method is most resistant to the highly influential observations. Justify your answer.

    I would choose the OLS method. Both LAD and HUB seem to be affected the same way as OLS after removing the highly influential points, so it would be to our benefit to choose the simpler overall model.
